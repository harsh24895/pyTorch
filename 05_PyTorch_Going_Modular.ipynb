{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHA49sDPYSxmvrbAIzdRKm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "What is going modular?\n",
        "\n",
        "Going modular involves turning notebook code (from a Jupyter Notebook or Google Colab notebook) into a series of different Python scripts that offer similar functionality.\n",
        "\n",
        "For example, we could turn our notebook code from a series of cells into the following Python files:\n",
        "\n",
        "data_setup.py - a file to prepare and download data if needed.\n",
        "engine.py - a file containing various training functions.\n",
        "model_builder.py or model.py - a file to create a PyTorch model.\n",
        "train.py - a file to leverage all other files and train a target PyTorch model.\n",
        "utils.py - a file dedicated to helpful utility functions.\n"
      ],
      "metadata": {
        "id": "KsVcSCzmxTLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Get Data\n",
        "Getting the data in each of the 05 notebooks happens the same as in notebook 04.\n",
        "\n",
        "A call is made to GitHub via Python's requests module to download a .zip file and unzip it."
      ],
      "metadata": {
        "id": "G5FGJZsH0Dy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download pizza, steak, sushi data\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "    print(\"Downloading pizza, steak, sushi data...\")\n",
        "    f.write(request.content)\n",
        "\n",
        "# Unzip pizza, steak, sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza, steak, sushi data...\")\n",
        "    zip_ref.extractall(image_path)\n",
        "\n",
        "# Remove zip file\n",
        "os.remove(data_path / \"pizza_steak_sushi.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqnzNAM00DjX",
        "outputId": "9697f2bc-c9ff-43b8-8007-e7dcde8b0ae0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory exists.\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup Dirs\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\""
      ],
      "metadata": {
        "id": "lCKeonQ_1Psr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Create Datasets and DataLoaders (data_setup.py)"
      ],
      "metadata": {
        "id": "8SK9zu5R1kAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Contains functionality for creating PyTorch DataLoaders for\n",
        "image classification data.\n",
        "\"\"\"\n",
        "import os\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir: str,\n",
        "    transform: transforms.Compose,\n",
        "    batch_size: int,\n",
        "    num_workers: int=NUM_WORKERS\n",
        "):"
      ],
      "metadata": {
        "id": "VtzfYntY1jtw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7080acec-c4fd-4425-feab-a9ef63e4b720"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-9-a6ebb0b21d78>, line 18)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-a6ebb0b21d78>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    ):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C3E8BmCM1jMg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}