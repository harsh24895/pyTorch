{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOI3nPBgyxNMFYhWqCWF2AE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the custom dataset and get my own data into pyTorch\n",
        "\n",
        "#0. Importing pytorch and setting up the device-agnostic code\n"
      ],
      "metadata": {
        "id": "VXifac8XmJ5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "#note: Pytorch 1.10+ is required for this step\n",
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RwPwKC5Mnb5i",
        "outputId": "884506be-ac35-4278-d099-bf3af24d0093"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.1+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setup device-agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bCU1PKUOoELF",
        "outputId": "54fb51cd-8756-4fb1-9e77-3015aacfccb4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get data for FOOD VISION MINI for our model"
      ],
      "metadata": {
        "id": "46ozLQgSoRYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# important: Food 101 dataset search in google it has multiple data for food item and been train and tested\n",
        "# we are working on small dataset comapre to Food101, we are using just 3-4classes of food an only 10% of images(75training, and 25 testing)\n",
        "\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "#set path to a data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "#If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory already exist... skipping download\")\n",
        "else:\n",
        "  print(f\"{image_path} does not exist, creating one..\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#Download pizza, steak and sushi data\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\") #just make sure we have raw file instead of blob in the link\n",
        "  print(\"Downloading pizza, steak, sushi data\")\n",
        "  f.write(request.content)\n",
        "\n",
        "#unzip pizz, steak, sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "  print(\"Unzipping pizz, steak and sushi data...\")\n",
        "  zip_ref.extractall(image_path) # in here it is extracting all the image file in the zip\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpQAFHvhomGR",
        "outputId": "23a6f3b3-e7eb-4bdc-81a8-5304f83e6572"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory already exist... skipping download\n",
            "Downloading pizza, steak, sushi data\n",
            "Unzipping pizz, steak and sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Becoming one with the data (data preparation and data exploration)"
      ],
      "metadata": {
        "id": "WOLtG1i32ph1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"Walks through dir_path returning its contents.\"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\" There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "VyIj8bBHuV28"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-heO59WDwiGT",
        "outputId": "6df2f66f-e74b-403c-efe0-f7bfa0cf326e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " There are 2 directories and 0 images in 'data/pizza_steak_sushi'.\n",
            " There are 3 directories and 0 images in 'data/pizza_steak_sushi/test'.\n",
            " There are 0 directories and 19 images in 'data/pizza_steak_sushi/test/steak'.\n",
            " There are 0 directories and 31 images in 'data/pizza_steak_sushi/test/sushi'.\n",
            " There are 0 directories and 25 images in 'data/pizza_steak_sushi/test/pizza'.\n",
            " There are 3 directories and 0 images in 'data/pizza_steak_sushi/train'.\n",
            " There are 0 directories and 75 images in 'data/pizza_steak_sushi/train/steak'.\n",
            " There are 0 directories and 72 images in 'data/pizza_steak_sushi/train/sushi'.\n",
            " There are 0 directories and 78 images in 'data/pizza_steak_sushi/train/pizza'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup train and testing path\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eqbm4f_w-U9",
        "outputId": "3a331045-52f2-4957-d6fe-dd5af6b25e6f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi/train'),\n",
              " PosixPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1 visualizing and image\n"
      ],
      "metadata": {
        "id": "T372nae6y_6b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7WofuGRKzbta"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}